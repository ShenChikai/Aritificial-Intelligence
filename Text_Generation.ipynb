{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShenChikai/Aritificial-Intelligence/blob/main/Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpUkaBBUanNv"
      },
      "source": [
        "<center> <h1> Language Models </h1> </center>\n",
        "\n",
        "In this homework, we will train character-level language model\n",
        "on a lyrics dataset.\n",
        "\n",
        "More specifically, we will:\n",
        "1. Implement a character-level language model based on LSTM.\n",
        "2. Train it on a lyrics dataset.\n",
        "3. Sample previously unseen lyrics from our model.\n",
        "4. Augment our model with an artist information.\n",
        "\n",
        "#### Google colaboratory\n",
        "\n",
        "Before getting started, get familiar with google colaboratory:\n",
        "https://colab.research.google.com/notebooks/welcome.ipynb\n",
        "\n",
        "This is a neat python environment that works in the cloud and does not require you to\n",
        "set up anything on your personal machine\n",
        "(it also has some built-in IDE features that make writing code easier).\n",
        "Moreover, it allows you to copy any existing collaboratory file, alter it and share\n",
        "with other people. In this homework, we will ask you to copy current colaboraty,\n",
        "complete all the tasks and share your colaboratory notebook with us so\n",
        "that we can grade it. We will also use colaboratory for the homework #4 so this\n",
        "homework will prepare you for it.\n",
        "\n",
        "#### Submission\n",
        "\n",
        "Before you start working on this homework do the following steps:\n",
        "\n",
        "1. Press __File > Save a copy in Drive...__ tab. This will allow you to have your own copy and change it.\n",
        "2. Follow all the steps in this collaboratory file and write/change/uncomment code as necessary.\n",
        "3. Do not forget to occasionally press __File > Save__ tab to save your progress.\n",
        "4. After all the changes are done and progress is saved press __Share__ button (top right corner of the page), press __get shareable link__ and make sure you have the option __Anyone with the link can view__ selected.\n",
        "5. Paste the link into your submission pdf file so that we can view it and grade.\n",
        "\n",
        "<center> <h2> Problem statement </h2> </center>\n",
        "\n",
        "In this homework we will train character-level language RNN model on lyrics dataset of most some artists. Having a trained model, we will sample a couple of songs which will be a mixture of different styles of different artists. After that we will update our model to become a conditional character-level RNN, making it possible for us to sample songs conditioned on artist.\n",
        "\n",
        "<center> <h2> Lyrics dataset </h2> </center>\n",
        "\n",
        "For our experiments we will use a subset of [Song Lyrics Kaggle dataset](https://www.kaggle.com/mousehead/songlyrics) which contains good variety of recent artists and more older ones. It is stored as a pandas file and we wrote a python wrapper around it to be able to use it for training purposes.\n",
        "\n",
        "<center> <h2> Character-Level language model </h2> </center>\n",
        "\n",
        "![alt text](http://warmspringwinds.github.io/assets/img/character_level_model.jpg \"Logo Title Text 1\")\n",
        "\n",
        "Before choosing a model, let’s have a closer look at our task. Given current letter and all previous letters, we will try to predict the next character. During training we will just take a sequence, and use all its characters except the last one as an input and the same sequence starting from the second character as groundtruth (see the picture above; Source).\n",
        "\n",
        "Our language model is defined on a character level. We will create a dictionary which will contain all English characters plus some special symbols, like period, comma, and end-of-line symbol. Each charecter will be represented as one-hot-encoded tensor. For more information about character-level models and examples, refer to the [the following resource](https://github.com/spro/practical-pytorch)\n",
        "\n",
        "\n",
        "Having characters, we can now form sequences of characters. What we would actually like to model is $p(current letter|all previous letters)$. At first, the task seems intractable as the number of previous letters is variable and it might become really large in case of long sequences. Turns out Reccurent Neural Netoworks can tackle this problem to a certain extent by using shared weights and fixed size hidden state. This leads us to a next section dedicated to RNNs.\n",
        "\n",
        "<center> <h2> Recurrent Neural Networks </h2> </center>\n",
        "\n",
        "![alt text](http://warmspringwinds.github.io/assets/img/rnn_unfold.jpg \"Logo Title Text 1\")\n",
        "\n",
        "Recurrent neural networks are a family of neural networks for processing sequential data. Unlike feedforward neural networks, RNNs can use their internal memory to process arbitrary sequences of inputs. Because of arbitrary size input sequences, they are concisely depicted as a graph with a cycle (see the picture; Source). But they can be “unfolded” if the size of input sequence is known. They define a non-linear mapping from a current input xt and previous hidden state st−1 to the output ot and current hidden state st. Hidden state size has a predefined size and stores features which are updated on each step and affect the result of mapping.\n",
        "\n",
        "Now align the previous picture of the character-level language model and the unfolded RNN picture to see how we are using the RNN model to learn a character level language model.\n",
        "\n",
        "While the picture depicts the Vanilla RNN, we will use LSTM in our work as it is easier to train usually achieves better results.\n",
        "\n",
        "For a more elaborate introduction to RNNs, we refer reader to [the following resource](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/).\n",
        "\n",
        "<center> <h2> Training unconditional character-level language model </h2> </center>\n",
        "\n",
        "Our first experiment consisted of training of our character-level language model RNN on the whole corpus. We didn’t take into consideration the artist information while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn83BquKZYC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "874b9c24-0472-491c-d943-3f6b64bc73d8"
      },
      "source": [
        "# Downloading dataset and installing dependencies\n",
        "!wget https://www.dropbox.com/s/ge1bhvik5jya9hr/songdata.csv?dl=0\n",
        "!mv songdata.csv\\?dl\\=0 songdata.csv\n",
        "!pip install livelossplot==0.3.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-20 22:49:07--  https://www.dropbox.com/s/ge1bhvik5jya9hr/songdata.csv?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ge1bhvik5jya9hr/songdata.csv [following]\n",
            "--2022-04-20 22:49:08--  https://www.dropbox.com/s/raw/ge1bhvik5jya9hr/songdata.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3f051ed68ad0f0251c6c63e403.dl.dropboxusercontent.com/cd/0/inline/BjyBQDd-IRX02937FFrbwhTnnAZo3IqYX0j9Fm0v8dtCISbxQD1q-782fP6pVWPN6m0EMKWh50m8cYxfDCgmrtyOCxCKSQfdO189aG1tel5XsI226AKPkl9J9T_MziPLDoDfN89zE6i2v5zZulZrpozVVwiM9NleNaLCOr50XJLBug/file# [following]\n",
            "--2022-04-20 22:49:08--  https://uc3f051ed68ad0f0251c6c63e403.dl.dropboxusercontent.com/cd/0/inline/BjyBQDd-IRX02937FFrbwhTnnAZo3IqYX0j9Fm0v8dtCISbxQD1q-782fP6pVWPN6m0EMKWh50m8cYxfDCgmrtyOCxCKSQfdO189aG1tel5XsI226AKPkl9J9T_MziPLDoDfN89zE6i2v5zZulZrpozVVwiM9NleNaLCOr50XJLBug/file\n",
            "Resolving uc3f051ed68ad0f0251c6c63e403.dl.dropboxusercontent.com (uc3f051ed68ad0f0251c6c63e403.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:601b:15::a27d:80f\n",
            "Connecting to uc3f051ed68ad0f0251c6c63e403.dl.dropboxusercontent.com (uc3f051ed68ad0f0251c6c63e403.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/plain]\n",
            "Saving to: ‘songdata.csv?dl=0’\n",
            "\n",
            "songdata.csv?dl=0   100%[===================>]  69.08M  82.0MB/s    in 0.8s    \n",
            "\n",
            "2022-04-20 22:49:09 (82.0 MB/s) - ‘songdata.csv?dl=0’ saved [72436445/72436445]\n",
            "\n",
            "Requirement already satisfied: livelossplot==0.3.4 in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.3.4) (5.3.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.3.4) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.3.4) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.3.4) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.3.4) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.3.4) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.3.4) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->livelossplot==0.3.4) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->livelossplot==0.3.4) (1.15.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.3.4) (4.9.2)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.3.4) (5.3.5)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.3.4) (1.8.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.3.4) (4.10.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.3.4) (0.2.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.3.4) (5.6.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.3.4) (5.3.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.3.4) (5.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.3.4) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.3.4) (0.13.3)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook->livelossplot==0.3.4) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook->livelossplot==0.3.4) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->livelossplot==0.3.4) (0.7.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook->livelossplot==0.3.4) (5.5.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.3.4) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.3.4) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.3.4) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.3.4) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.3.4) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.3.4) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.3.4) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot==0.3.4) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->livelossplot==0.3.4) (2.0.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->livelossplot==0.3.4) (5.0.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->livelossplot==0.3.4) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->livelossplot==0.3.4) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->livelossplot==0.3.4) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->livelossplot==0.3.4) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook->livelossplot==0.3.4) (0.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->livelossplot==0.3.4) (2.15.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->livelossplot==0.3.4) (4.3.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->livelossplot==0.3.4) (4.11.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->livelossplot==0.3.4) (5.7.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->livelossplot==0.3.4) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->livelossplot==0.3.4) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook->livelossplot==0.3.4) (3.8.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook->livelossplot==0.3.4) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECL2lbFPUF42"
      },
      "source": [
        "First, let us create a dictionary, we will use $100$ characters and some special symbols including $\\n$ which will allow our generator to also decide when the current line should end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DRgqtnoUmzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39de2ffb-0ccb-4364-a54b-a8b8c9fd665f"
      },
      "source": [
        "import torch\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "\n",
        "\n",
        "all_characters = string.printable\n",
        "number_of_characters = len(all_characters)\n",
        "\n",
        "print(all_characters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4VmJMSmVGMa"
      },
      "source": [
        "Below we will define some helper functions that will help us to convert character to corresponding\n",
        "labels that we will use for actual training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl5JpbLFVZ45"
      },
      "source": [
        "def character_to_label(character):\n",
        "    \n",
        "    character_label = all_characters.find(character)\n",
        "        \n",
        "    return character_label\n",
        "\n",
        "\n",
        "def string_to_labels(character_string):\n",
        "    \n",
        "    return list(map(lambda character: character_to_label(character), character_string))\n",
        "\n",
        "  \n",
        "def pad_sequence(seq, max_length, pad_label=100):\n",
        "    \n",
        "    seq += [pad_label for i in range(max_length - len(seq))]\n",
        "    \n",
        "    return seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QcAVw7AVhK8"
      },
      "source": [
        "Now we will define a dataset class that will take care of loading data from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PioOgKILVqfv"
      },
      "source": [
        "\n",
        "# The class works in two modes: train and validation, which we will\n",
        "# use during training\n",
        "\n",
        "# It also padds data so that all sequences are of the same length.\n",
        "# We need this because otherwise efficient batching will not work\n",
        "# and we will not be able to use GPU processing to the full extent\n",
        "class LyricsGenerationDataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self, csv_file_path,\n",
        "                 minimum_song_count=None,\n",
        "                 artists=None,\n",
        "                 train=True):\n",
        "        \n",
        "        \n",
        "        self.lyrics_dataframe = pd.read_csv(csv_file_path)\n",
        "        \n",
        "        if artists:\n",
        "            \n",
        "            self.lyrics_dataframe = self.lyrics_dataframe[self.lyrics_dataframe.artist.isin(artists)]\n",
        "            self.lyrics_dataframe = self.lyrics_dataframe.reset_index()\n",
        "        \n",
        "        if minimum_song_count:\n",
        "        \n",
        "            # Getting artists that have 70+ songs\n",
        "            self.lyrics_dataframe = self.lyrics_dataframe.groupby('artist').filter(lambda x: len(x) > minimum_song_count)\n",
        "            # Reindex .loc after we fetched random songs\n",
        "            self.lyrics_dataframe = self.lyrics_dataframe.reset_index()\n",
        "        \n",
        "        # Get the length of the biggest lyric text\n",
        "        # We will need that for padding\n",
        "        self.max_text_len = self.lyrics_dataframe.text.str.len().max()\n",
        "        \n",
        "        whole_dataset_len = len(self.lyrics_dataframe)\n",
        "        \n",
        "        self.indexes = range(whole_dataset_len)\n",
        "        \n",
        "        if train:\n",
        "          \n",
        "          self.indexes = self.indexes[500:]\n",
        "          \n",
        "        else:\n",
        "          self.indexes = self.indexes[:500]\n",
        "        \n",
        "        self.artists_list = list(self.lyrics_dataframe.artist.unique())\n",
        "        \n",
        "        self.number_of_artists = len(self.artists_list)\n",
        "    \n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.indexes)\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        index = self.indexes[index]\n",
        "        \n",
        "        sequence_raw_string = self.lyrics_dataframe.loc[index].text\n",
        "        \n",
        "        sequence_string_labels = string_to_labels(sequence_raw_string)\n",
        "        \n",
        "        sequence_length = len(sequence_string_labels) - 1\n",
        "        \n",
        "        # Shifted by one char\n",
        "        input_string_labels = sequence_string_labels[:-1]\n",
        "        output_string_labels = sequence_string_labels[1:]\n",
        "                \n",
        "        # pad sequence so that all of them have the same lenght\n",
        "        # Otherwise the batching won't work\n",
        "        input_string_labels_padded = pad_sequence(input_string_labels, max_length=self.max_text_len)\n",
        "        \n",
        "        # Filling in sequences with a '-100' lable -- this way it is omitted\n",
        "        # in cross_entropy_loss\n",
        "        output_string_labels_padded = pad_sequence(output_string_labels, max_length=self.max_text_len, pad_label=-100)\n",
        "        \n",
        "        return (torch.LongTensor(input_string_labels_padded),\n",
        "                torch.LongTensor(output_string_labels_padded),\n",
        "                torch.LongTensor([sequence_length]) )\n",
        "\n",
        "# Here are the artists\n",
        "artists = [\n",
        "'ABBA',\n",
        "'Ace Of Base',\n",
        "'Backstreet Boys',\n",
        "'Bob Marley',\n",
        "'Bon Jovi',\n",
        "'Britney Spears',\n",
        "'Bruno Mars',\n",
        "'Coldplay',\n",
        "'Ed Sheeran',\n",
        "'Elton John',\n",
        "'Elvis Presley',\n",
        "'Eminem',\n",
        "'Evanescence',\n",
        "'Fall Out Boy',\n",
        "'Foo Fighters',\n",
        "'Green Day',\n",
        "'HIM',\n",
        "'Imagine Dragons',\n",
        "'Justin Bieber',\n",
        "'Justin Timberlake',\n",
        "'Katy Perry',\n",
        "'Lady Gaga',\n",
        "'Lana Del Rey',\n",
        "'Linkin Park',\n",
        "'Madonna',\n",
        "'Marilyn Manson',\n",
        "'Maroon 5',\n",
        "'Metallica',\n",
        "'Michael Jackson',\n",
        "'Nickelback',\n",
        "'Oasis',\n",
        "'One Direction',\n",
        "'P!nk',\n",
        "'Queen',\n",
        "'Red Hot Chili Peppers',\n",
        "'Rihanna',\n",
        "'Robbie Williams',\n",
        "'Sting',\n",
        "'The Script',\n",
        "'Weezer',\n",
        "'Yellowcard']\n",
        "\n",
        "trainset = LyricsGenerationDataset(csv_file_path='songdata.csv', artists=artists)\n",
        "valset = LyricsGenerationDataset(csv_file_path='songdata.csv', artists=artists, train=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcRWxDZmWZN8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "7f45e5d7-e1b1-4c91-95c4-01bd6cc823f9"
      },
      "source": [
        "# Let us inspect the dataset quickly\n",
        "trainset.lyrics_dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      index      artist                   song  \\\n",
              "0         0        ABBA  Ahe's My Kind Of Girl   \n",
              "1         1        ABBA       Andante, Andante   \n",
              "2         2        ABBA         As Good As New   \n",
              "3         3        ABBA                   Bang   \n",
              "4         4        ABBA       Bang-A-Boomerang   \n",
              "...     ...         ...                    ...   \n",
              "4793  57175  Yellowcard        The Finish Line   \n",
              "4794  57176  Yellowcard           Twenty Three   \n",
              "4795  57177  Yellowcard           Waiting Game   \n",
              "4796  57178  Yellowcard               Way Away   \n",
              "4797  57179  Yellowcard   Words, Hands, Hearts   \n",
              "\n",
              "                                                link  \\\n",
              "0         /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
              "1              /a/abba/andante+andante_20002708.html   \n",
              "2               /a/abba/as+good+as+new_20003033.html   \n",
              "3                         /a/abba/bang_20598415.html   \n",
              "4             /a/abba/bang+a+boomerang_20002668.html   \n",
              "...                                              ...   \n",
              "4793     /y/yellowcard/the+finish+line_10195563.html   \n",
              "4794        /y/yellowcard/twenty+three_10195543.html   \n",
              "4795        /y/yellowcard/waiting+game_20423993.html   \n",
              "4796            /y/yellowcard/way+away_10195536.html   \n",
              "4797  /y/yellowcard/words+hands+hearts_20424033.html   \n",
              "\n",
              "                                                   text  \n",
              "0     Look at her face, it's a wonderful face  \\nAnd...  \n",
              "1     Take it easy with me, please  \\nTouch me gentl...  \n",
              "2     I'll never know why I had to go  \\nWhy I had t...  \n",
              "3     Making somebody happy is a question of give an...  \n",
              "4     Making somebody happy is a question of give an...  \n",
              "...                                                 ...  \n",
              "4793  Hello friend, it's been too long and every tow...  \n",
              "4794  I got to tell you that he waited all his life ...  \n",
              "4795  You and me  \\nA little different  \\nThough we ...  \n",
              "4796  I think I'm breaking out  \\nI'm gonna leave yo...  \n",
              "4797  The whole world was sleeping  \\nAnd I was ther...  \n",
              "\n",
              "[4798 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0096b37b-bc78-48d4-8f79-b151c892e0f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>artist</th>\n",
              "      <th>song</th>\n",
              "      <th>link</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ABBA</td>\n",
              "      <td>Ahe's My Kind Of Girl</td>\n",
              "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
              "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ABBA</td>\n",
              "      <td>Andante, Andante</td>\n",
              "      <td>/a/abba/andante+andante_20002708.html</td>\n",
              "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ABBA</td>\n",
              "      <td>As Good As New</td>\n",
              "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
              "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ABBA</td>\n",
              "      <td>Bang</td>\n",
              "      <td>/a/abba/bang_20598415.html</td>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ABBA</td>\n",
              "      <td>Bang-A-Boomerang</td>\n",
              "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4793</th>\n",
              "      <td>57175</td>\n",
              "      <td>Yellowcard</td>\n",
              "      <td>The Finish Line</td>\n",
              "      <td>/y/yellowcard/the+finish+line_10195563.html</td>\n",
              "      <td>Hello friend, it's been too long and every tow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4794</th>\n",
              "      <td>57176</td>\n",
              "      <td>Yellowcard</td>\n",
              "      <td>Twenty Three</td>\n",
              "      <td>/y/yellowcard/twenty+three_10195543.html</td>\n",
              "      <td>I got to tell you that he waited all his life ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>57177</td>\n",
              "      <td>Yellowcard</td>\n",
              "      <td>Waiting Game</td>\n",
              "      <td>/y/yellowcard/waiting+game_20423993.html</td>\n",
              "      <td>You and me  \\nA little different  \\nThough we ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>57178</td>\n",
              "      <td>Yellowcard</td>\n",
              "      <td>Way Away</td>\n",
              "      <td>/y/yellowcard/way+away_10195536.html</td>\n",
              "      <td>I think I'm breaking out  \\nI'm gonna leave yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>57179</td>\n",
              "      <td>Yellowcard</td>\n",
              "      <td>Words, Hands, Hearts</td>\n",
              "      <td>/y/yellowcard/words+hands+hearts_20424033.html</td>\n",
              "      <td>The whole world was sleeping  \\nAnd I was ther...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4798 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0096b37b-bc78-48d4-8f79-b151c892e0f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0096b37b-bc78-48d4-8f79-b151c892e0f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0096b37b-bc78-48d4-8f79-b151c892e0f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVfxEdLIC_TR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91dfc27-b528-4577-e7a1-32decc883caa"
      },
      "source": [
        "len(trainset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4298"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-O9_bPEEeak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf7da73-3fb2-4244-e081-b47bda90aa66"
      },
      "source": [
        "len(valset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTikd1ZRa6tC"
      },
      "source": [
        "Below, we are defining an RNN class, and will ask you to feel out missing parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4ReYbD3a5ka"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 input_size=101,\n",
        "                 hidden_size=512,\n",
        "                 num_classes=100,\n",
        "                 n_layers=2):\n",
        "        \n",
        "        # input_size = 101 -- 100 characters + background character\n",
        "        # num_classes = 100 -- we predict what character goes next\n",
        "        \n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_classes = num_classes\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        \n",
        "        # input_size -- size of the dictionary + 1 (accounts for padding constant)\n",
        "        \n",
        "        # Below use nn.Embedding to map from input_size to hidden_size\n",
        "        # nn.Embedding converts labels into one-hot encoding and runs a linear\n",
        "        # layer on each of the converted one-hot encoded elements\n",
        "        self.embedder = nn.Embedding(self.input_size, self.hidden_size)\n",
        "        \n",
        "        # Below use nn.LSTM that accepts hidden_size as input size,\n",
        "        # and has hidden size equal to hidden_size argument and\n",
        "        # n_layers\n",
        "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size, self.n_layers, batch_first=True)\n",
        "\n",
        "        \n",
        "        # Below use nn.Linear to make representation of hidden_size\n",
        "        # to the number of classes that will be fed to softmax\n",
        "        # to decide which character goes next\n",
        "        self.logits_fc = nn.Linear(self.hidden_size, self.num_classes)\n",
        "    \n",
        "    \n",
        "    def forward(self,\n",
        "                input_sequences,\n",
        "                input_sequences_lengths,\n",
        "                hidden=None):\n",
        "        \n",
        "        batch_size = input_sequences.shape[1]\n",
        "\n",
        "        embedded = self.embedder(input_sequences)\n",
        "        \n",
        "        # This is needed for efficient processing of sequences of\n",
        "        # variable lengths. Feel free to skip\n",
        "        # Here we run rnns only on non-padded regions of the batch\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_sequences_lengths)\n",
        "        outputs, hidden = self.lstm(packed, hidden)\n",
        "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
        "        \n",
        "        \n",
        "        logits = self.logits_fc(outputs)\n",
        "        # This is needed for cross entropy loss\n",
        "        logits = logits.transpose(0, 1).contiguous()\n",
        "        logits_flatten = logits.view(-1, self.num_classes)\n",
        "        \n",
        "        return logits_flatten, hidden\n",
        "\n",
        "# for efficient processing of sequences of\n",
        "# variable lengths. Feel free to skip \n",
        "def post_process_sequence_batch(batch_tuple):\n",
        "  \n",
        "  input_sequences, output_sequences, lengths = batch_tuple\n",
        "\n",
        "  splitted_input_sequence_batch = input_sequences.split(split_size=1)\n",
        "  splitted_output_sequence_batch = output_sequences.split(split_size=1)\n",
        "  splitted_lengths_batch = lengths.split(split_size=1)\n",
        "\n",
        "  training_data_tuples = zip(splitted_input_sequence_batch,\n",
        "                             splitted_output_sequence_batch,\n",
        "                             splitted_lengths_batch)\n",
        "\n",
        "  training_data_tuples_sorted = sorted(training_data_tuples,\n",
        "                                       key=lambda p: int(p[2]),\n",
        "                                       reverse=True)\n",
        "\n",
        "  splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n",
        "\n",
        "  input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n",
        "  output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n",
        "  lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n",
        "\n",
        "  input_sequence_batch_sorted = input_sequence_batch_sorted[:, :lengths_batch_sorted[0, 0]]\n",
        "  output_sequence_batch_sorted = output_sequence_batch_sorted[:, :lengths_batch_sorted[0, 0]]\n",
        "\n",
        "  input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n",
        "\n",
        "  # pytorch's api for rnns wants lenghts to be list of ints\n",
        "  lengths_batch_sorted_list = list(lengths_batch_sorted)\n",
        "  lengths_batch_sorted_list = list(map(lambda x: int(x), lengths_batch_sorted_list))\n",
        "\n",
        "\n",
        "  return input_sequence_batch_transposed, output_sequence_batch_sorted, lengths_batch_sorted_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYFqPtAGkZuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072e1c3f-b41d-4505-be25-a14d87faf6f3"
      },
      "source": [
        "trainset_loader = torch.utils.data.DataLoader(trainset,\n",
        "                                              batch_size=50,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=4,\n",
        "                                              drop_last=True)\n",
        "\n",
        "\n",
        "valset_loader = torch.utils.data.DataLoader(valset,\n",
        "                                            batch_size=50,\n",
        "                                            shuffle=True,\n",
        "                                            num_workers=1,\n",
        "                                            drop_last=True)\n",
        "\n",
        "\n",
        "rnn = RNN(input_size=len(all_characters) + 1, hidden_size=512, num_classes=len(all_characters))\n",
        "rnn.cuda()\n",
        "\n",
        "#TODO? Try different learning rates and optimizers\n",
        "\n",
        "# learning_rate = 0.001\n",
        "# optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
        "\n",
        "# -SGD not working\n",
        "# learning_rate = 0.005\n",
        "# optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "learning_rate = 0.005\n",
        "optimizer = torch.optim.AdamW(rnn.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcZ4YAw6qqSZ"
      },
      "source": [
        "from livelossplot import PlotLosses\n",
        "\n",
        "liveloss = PlotLosses()\n",
        "\n",
        "# We will get back to this function later on,\n",
        "# Just ignore it so far -- we will use it to generate\n",
        "# samples during our training\n",
        "def sample_from_rnn(starting_string=\"I\", sample_length=300, temperature=0.5):\n",
        "    assert temperature >= 0.0\n",
        "    sampled_string = starting_string\n",
        "    hidden = None\n",
        "\n",
        "    first_input = torch.LongTensor( string_to_labels(starting_string) ).cuda()\n",
        "    first_input = first_input.unsqueeze(1)\n",
        "    current_input = first_input\n",
        "\n",
        "    output, hidden = rnn(current_input, [len(sampled_string)], hidden=hidden)\n",
        "\n",
        "    output = output[-1, :].unsqueeze(0)\n",
        "\n",
        "    for i in range(sample_length):\n",
        "\n",
        "        output_dist = nn.functional.softmax( output.view(-1).div(temperature + 1e-4) ).data\n",
        "\n",
        "        predicted_label = torch.multinomial(output_dist, 1)\n",
        "\n",
        "        sampled_string += all_characters[int(predicted_label[0])]\n",
        "\n",
        "        current_input = predicted_label.unsqueeze(1)\n",
        "\n",
        "        output, hidden = rnn(current_input, [1], hidden=hidden)\n",
        "    \n",
        "    return sampled_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlU73odMlbrR",
        "outputId": "3f20e812-dfd4-456f-f9da-b810f28a474b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "epochs_number = 8\n",
        "\n",
        "\n",
        "for epoch_number in range(epochs_number):\n",
        "\n",
        "    for batch in trainset_loader:\n",
        "\n",
        "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        "\n",
        "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        "\n",
        "        output_sequences_batch_var =  output_sequences_batch.contiguous().view(-1).cuda()\n",
        "        input_sequences_batch_var = input_sequences_batch.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logits, _ = rnn(input_sequences_batch_var, sequences_lengths)\n",
        "        \n",
        "        \n",
        "        train_loss = criterion(logits, output_sequences_batch_var)\n",
        "        \n",
        "        train_loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "    \n",
        "    \n",
        "    val_loss_list = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      \n",
        "      for batch in valset_loader:\n",
        "\n",
        "        post_processed_batch_tuple = post_process_sequence_batch(batch)\n",
        "\n",
        "        input_sequences_batch, output_sequences_batch, sequences_lengths = post_processed_batch_tuple\n",
        "\n",
        "        output_sequences_batch_var =  output_sequences_batch.contiguous().view(-1).cuda()\n",
        "        input_sequences_batch_var = input_sequences_batch.cuda()\n",
        "        \n",
        "        logits, _ = rnn(input_sequences_batch_var, sequences_lengths)\n",
        "        loss = criterion(logits, output_sequences_batch_var)\n",
        "        \n",
        "        val_loss_list.append(loss.item())\n",
        "      \n",
        "    liveloss.update({'Validation loss': sum(val_loss_list) / len(val_loss_list),\n",
        "                     'Training loss': train_loss.item()})\n",
        "    liveloss.draw()\n",
        "    \n",
        "    print('Example of a text generated by current model:')\n",
        "    print(sample_from_rnn(starting_string='I', temperature=0.5))\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss:\n",
            "training   (min:    1.322, max:    2.112, cur:    1.322)\n",
            "\n",
            "Training loss:\n",
            "training   (min:    1.351, max:    2.139, cur:    1.357)\n",
            "Example of a text generated by current model:\n",
            "I'm gonna start  \n",
            "  \n",
            "Heart and out of the wall  \n",
            "  \n",
            "I said what you can't get a strong  \n",
            "  \n",
            "[Chorus]  \n",
            "So I know what I want to start  \n",
            "I want to say to love that I believe  \n",
            "  \n",
            "For your hearts  \n",
            "Could be your best  \n",
            "Don't know the sure and like the wrong  \n",
            "And I'm so turn  \n",
            "I got to the should be th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmeuHzsHf4pS"
      },
      "source": [
        "<center> <h2> Text Generation </h2> </center>\n",
        "\n",
        "During the text generation process we can define a starting prefix of characters that our model will condition on and generate the rest of the sequence. \n",
        "\n",
        "The model generates each new token (characters in our case) by sampling from the output probability distribution. When sampling, we can set a `temperature` parameter that controls the randomness of the sampling process. When this parameter approaches zero, the sampling is equivalent to argmax and when it is close to infinity the sampling is equivalent to sampling from a uniform distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASBCO64tnBkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8286161e-d231-47fb-bde3-fce32059355c"
      },
      "source": [
        "def sample_from_rnn(starting_string=\"Why\", sample_length=300, temperature=1):\n",
        "    assert temperature >= 0.0\n",
        "    sampled_string = starting_string\n",
        "    hidden = None\n",
        "\n",
        "    first_input = torch.LongTensor( string_to_labels(starting_string) ).cuda()\n",
        "    first_input = first_input.unsqueeze(1)\n",
        "    current_input = first_input\n",
        "\n",
        "    output, hidden = rnn(current_input, [len(sampled_string)], hidden=hidden)\n",
        "\n",
        "    output = output[-1, :].unsqueeze(0)\n",
        "\n",
        "    for i in range(sample_length):\n",
        "\n",
        "        output_dist = nn.functional.softmax( output.view(-1).div(temperature + 1e-4) ).data\n",
        "\n",
        "        predicted_label = torch.multinomial(output_dist, 1)\n",
        "\n",
        "        sampled_string += all_characters[int(predicted_label[0])]\n",
        "\n",
        "        current_input = predicted_label.unsqueeze(1)\n",
        "\n",
        "        output, hidden = rnn(current_input, [1], hidden=hidden)\n",
        "    \n",
        "    return sampled_string\n",
        "\n",
        "#TODO? Try sampling with different temperatures and starting sequences\n",
        "# What do you observe? (See the pdf)\n",
        "print(sample_from_rnn(starting_string='I', temperature=0.1))\n",
        "print(\"----------------------------------\")\n",
        "print(sample_from_rnn(starting_string='I', temperature=0.8))\n",
        "print(\"----------------------------------\")\n",
        "print(sample_from_rnn(starting_string='Whatever I want', temperature=0.4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to the way  \n",
            "I want to the way  \n",
            "I want to the way  \n",
            "I want to the way  \n",
            "  \n",
            "I want to the start  \n",
            "  \n",
            "I want to be the started  \n",
            "  \n",
            "I want to be the start  \n",
            "I want to the way  \n",
            "  \n",
            "I want to the start  \n",
            "  \n",
            "I want to the street  \n",
            "  \n",
            "I want to the way  \n",
            "  \n",
            "I want to the start  \n",
            "  \n",
            "I want to the wa\n",
            "----------------------------------\n",
            "In the shelf  \n",
            "Of like hurts and baby name  \n",
            "In the could breathe  \n",
            "We were warning  \n",
            "Don't make it  \n",
            "But I know you  \n",
            "In the night to it on your shoose you come a sapposers to see it that wild out  \n",
            "  \n",
            "Learned, bad really love  \n",
            "It's you, I wants girl  \n",
            "I'm heaving home  \n",
            "  \n",
            "Miller  \n",
            "  \n",
            "Let me try t\n",
            "----------------------------------\n",
            "Whatever I want to you  \n",
            "  \n",
            "I want to the same  \n",
            "I'm a don't make me home  \n",
            "  \n",
            "I'm a could take the light  \n",
            "  \n",
            "I know the start  \n",
            "This is the still the heart  \n",
            "And I'm the world  \n",
            "When I want you to see  \n",
            "  \n",
            "[Chorus]  \n",
            "  \n",
            "But the started  \n",
            "I walk to me  \n",
            "You're baby  \n",
            "  \n",
            "I don't want to be a body  \n",
            "  \n",
            "[Chorus]  \n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Observation**: \n",
        "1. The starting sequences determine the direction of the first sentence and potential the followings.\n",
        "2. The higher the temperature, the more grammar/style/complexity the generated lyrics has."
      ],
      "metadata": {
        "id": "lzQ_pgQ8mtC8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3M1ge3miqXv"
      },
      "source": [
        "<center> <h2> Conditional Model (Optional) </h2> </center>\n",
        "So far our RNN has been trained on lyrics from all the songs without knowledge of which artists.\n",
        "\n",
        "Next, we will give the RNN additional information, the class representing the artist who made the song.\n",
        "\n",
        "Below we provide updated functions and dataset class that can be used to train language model that is conditioned on the artist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moBszIsDinEW"
      },
      "source": [
        "class LyricsGenerationDatasetConditional(data.Dataset):\n",
        "    \n",
        "    def __init__(self, csv_file_path, minimum_song_count=None, artists=None):\n",
        "        \n",
        "        \n",
        "        self.lyrics_dataframe = pd.read_csv(csv_file_path)\n",
        "        \n",
        "        if artists:\n",
        "            \n",
        "            self.lyrics_dataframe = self.lyrics_dataframe[self.lyrics_dataframe.artist.isin(artists)]\n",
        "            self.lyrics_dataframe = self.lyrics_dataframe.reset_index()\n",
        "        \n",
        "        if minimum_song_count:\n",
        "        \n",
        "            # Getting artists that have 70+ songs\n",
        "            self.lyrics_dataframe = self.lyrics_dataframe.groupby('artist').filter(lambda x: len(x) > minimum_song_count)\n",
        "            # Reindex .loc after we fetched random songs\n",
        "            self.lyrics_dataframe = self.lyrics_dataframe.reset_index()\n",
        "        \n",
        "        # Get the length of the biggest lyric text\n",
        "        # We will need that for padding\n",
        "        self.max_text_len = self.lyrics_dataframe.text.str.len().max()\n",
        "        \n",
        "        whole_dataset_len = len(self.lyrics_dataframe)\n",
        "        \n",
        "        self.indexes = range(whole_dataset_len)\n",
        "        \n",
        "        \n",
        "        # Let's get unique artists and form a list\n",
        "        self.artists_list = list(self.lyrics_dataframe.artist.unique())\n",
        "        \n",
        "        # We will need the overall number of artists for \n",
        "        self.number_of_artists = len(self.artists_list)\n",
        "    \n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.indexes)\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        index = self.indexes[index]\n",
        "        \n",
        "        sequence_raw_string = self.lyrics_dataframe.loc[index].text\n",
        "        \n",
        "        sequence_string_labels = string_to_labels(sequence_raw_string)\n",
        "        \n",
        "        sequence_length = len(sequence_string_labels) - 1\n",
        "        \n",
        "        # Shifted by one char\n",
        "        input_string_labels = sequence_string_labels[:-1]\n",
        "        output_string_labels = sequence_string_labels[1:]\n",
        "                \n",
        "        # pad sequence so that all of them have the same lenght\n",
        "        # Otherwise the batching won't work\n",
        "        input_string_labels_padded = pad_sequence(input_string_labels, max_length=self.max_text_len)\n",
        "        \n",
        "        output_string_labels_padded = pad_sequence(output_string_labels, max_length=self.max_text_len, pad_label=-100)\n",
        "        \n",
        "        ## Adding the artist label\n",
        "        sequence_raw_artist_name_string = self.lyrics_dataframe.loc[index].artist\n",
        "\n",
        "        sequence_artist_label = self.artists_list.index(sequence_raw_artist_name_string)\n",
        "        \n",
        "        return (torch.LongTensor(input_string_labels_padded),\n",
        "                torch.LongTensor(output_string_labels_padded),\n",
        "                torch.LongTensor([sequence_artist_label]),\n",
        "                torch.LongTensor([sequence_length]) )\n",
        "\n",
        "    \n",
        "def post_process_sequence_batch_conditional(batch_tuple):\n",
        "    \n",
        "    input_sequences, output_sequences, artists, lengths = batch_tuple\n",
        "    \n",
        "    splitted_input_sequence_batch = input_sequences.split(split_size=1)\n",
        "    splitted_output_sequence_batch = output_sequences.split(split_size=1)\n",
        "    splitted_artists_batch = artists.split(split_size=1)\n",
        "    splitted_lengths_batch = lengths.split(split_size=1)\n",
        "\n",
        "    training_data_tuples = zip(splitted_input_sequence_batch,\n",
        "                               splitted_output_sequence_batch,\n",
        "                               splitted_artists_batch,\n",
        "                               splitted_lengths_batch)\n",
        "\n",
        "    training_data_tuples_sorted = sorted(training_data_tuples,\n",
        "                                         key=lambda p: int(p[3]),\n",
        "                                         reverse=True)\n",
        "\n",
        "    splitted_input_sequence_batch, splitted_output_sequence_batch, splitted_artists_batch, splitted_lengths_batch = zip(*training_data_tuples_sorted)\n",
        "\n",
        "    input_sequence_batch_sorted = torch.cat(splitted_input_sequence_batch)\n",
        "    output_sequence_batch_sorted = torch.cat(splitted_output_sequence_batch)\n",
        "    artists_batch_sorted = torch.cat(splitted_artists_batch)\n",
        "    lengths_batch_sorted = torch.cat(splitted_lengths_batch)\n",
        "    \n",
        "    \n",
        "    # Here we trim overall data matrix using the size of the longest sequence\n",
        "    input_sequence_batch_sorted = input_sequence_batch_sorted[:, :lengths_batch_sorted[0, 0]]\n",
        "    output_sequence_batch_sorted = output_sequence_batch_sorted[:, :lengths_batch_sorted[0, 0]]\n",
        "    \n",
        "    # We should probably repeat this over the whole input sequence\n",
        "    artists_batch_sorted = artists_batch_sorted.expand_as(input_sequence_batch_sorted)\n",
        "\n",
        "    input_sequence_batch_transposed = input_sequence_batch_sorted.transpose(0, 1)\n",
        "    artists_batch_sorted_transposed = artists_batch_sorted.transpose(0, 1)\n",
        "    \n",
        "    # pytorch's api for rnns wants lenghts to be list of ints\n",
        "    lengths_batch_sorted_list = list(lengths_batch_sorted)\n",
        "    lengths_batch_sorted_list = list(map(lambda x: int(x), lengths_batch_sorted_list))\n",
        "    \n",
        "    return input_sequence_batch_transposed, output_sequence_batch_sorted, artists_batch_sorted_transposed, lengths_batch_sorted_list\n",
        "\n",
        "\n",
        "class RNN_Conditional(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, num_classes, num_conditions, n_layers=2):\n",
        "        \n",
        "        super(RNN_Conditional, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_classes = num_classes\n",
        "        self.n_layers = n_layers\n",
        "        self.num_conditions = num_conditions\n",
        "        \n",
        "        # Converts labels into one-hot encoding and runs a linear\n",
        "        # layer on each of the converted one-hot encoded elements\n",
        "        \n",
        "        # input_size -- size of the dictionary + 1 (accounts for padding constant)\n",
        "        \n",
        "        \n",
        "        self.characters_embedder = # TODO: complete this line\n",
        "        \n",
        "        self.artist_embedder = # TODO: complete this line\n",
        "        \n",
        "        self.lstm = nn.LSTM(hidden_size * 2, #, #) # TODO: complete this line\n",
        "        \n",
        "        self.logits_fc = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "    def forward(self, input_sequences, input_sequences_conditions, input_sequences_lengths, hidden=None):\n",
        "        \n",
        "        batch_size = input_sequences.shape[1]\n",
        "\n",
        "        characters_embedded = self.characters_embedder(input_sequences)\n",
        "        conditions_embedded = self.artist_embedder(input_sequences_conditions)\n",
        "        \n",
        "        embedded_combined = torch.cat((characters_embedded, conditions_embedded), dim=2)\n",
        "\n",
        "        # Here we run rnns only on non-padded regions of the batch\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded_combined, input_sequences_lengths)\n",
        "        outputs, hidden = self.lstm(packed, hidden)\n",
        "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
        "        \n",
        "        logits = self.logits_fc(outputs)\n",
        "        \n",
        "        logits = logits.transpose(0, 1).contiguous()\n",
        "        \n",
        "        logits_flatten = logits.view(-1, self.num_classes)\n",
        "        \n",
        "        return logits_flatten, hidden\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2M_XXJOnkkH"
      },
      "source": [
        "def sample_from_rnn_conditionally(starting_string=\"Why\", sample_length=300, temperature=1, artist_label=0):\n",
        "    \n",
        "    sampled_string = starting_string\n",
        "    hidden = None\n",
        "\n",
        "    first_input = torch.LongTensor( string_to_labels(starting_string) ).cuda()\n",
        "    first_input = first_input.unsqueeze(1)\n",
        "\n",
        "    # Expand the artist label to have the same size as input sequence\n",
        "    # we duplicate it in every input\n",
        "    artist_label_input = torch.LongTensor([artist_label]).expand_as(first_input)\n",
        "\n",
        "    current_sequence_input = first_input\n",
        "    current_artist_input = artist_label_input.cuda()\n",
        "\n",
        "    output, hidden = rnn(current_sequence_input, current_artist_input, [len(sampled_string)], hidden=hidden)\n",
        "\n",
        "    output = output[-1, :].unsqueeze(0)\n",
        "\n",
        "    for i in range(sample_length):\n",
        "\n",
        "        output_dist = nn.functional.softmax( output.view(-1).div(temperature) ).data\n",
        "\n",
        "        predicted_label = torch.multinomial(output_dist, 1)\n",
        "\n",
        "        sampled_string += all_characters[int(predicted_label[0])]\n",
        "        current_sequence_input = predicted_label.unsqueeze(1)\n",
        "\n",
        "        artist_label_input = torch.LongTensor([artist_label]).expand_as(current_sequence_input)\n",
        "        current_artist_input = artist_label_input.cuda()\n",
        "\n",
        "        output, hidden = rnn(current_sequence_input, current_artist_input, [1], hidden=hidden)\n",
        "    \n",
        "    return sampled_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcPuMC_PlR24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b942fd30-e85b-45e2-bdd6-b9c2b29ab0af"
      },
      "source": [
        "trainset = LyricsGenerationDatasetConditional(csv_file_path='songdata.csv', artists=artists)\n",
        "\n",
        "trainset_loader = torch.utils.data.DataLoader(trainset,\n",
        "                                              batch_size=50,\n",
        "                                              shuffle=True, num_workers=4, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Td2XXulwkz"
      },
      "source": [
        "rnn = RNN_Conditional(input_size=len(all_characters) + 1,\n",
        "          hidden_size=512,\n",
        "          num_classes=len(all_characters),\n",
        "          num_conditions=trainset.number_of_artists)\n",
        "\n",
        "rnn.cuda()\n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eayQjtpZmTwU"
      },
      "source": [
        "from livelossplot import PlotLosses\n",
        "\n",
        "liveloss_train = PlotLosses()\n",
        "liveloss_val = PlotLosses()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5yU-5anl4st",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "0c5af19d-9ccb-4dcf-be26-754c4c07c096"
      },
      "source": [
        "# Conditional model takes more to converge,\n",
        "# Try training for more epochs for better results\n",
        "epochs_number = 5000\n",
        "\n",
        "for epoch_number in range(epochs_number):\n",
        "\n",
        "    for batch in trainset_loader:\n",
        "\n",
        "        post_processed_batch_tuple = post_process_sequence_batch_conditional(batch)\n",
        "\n",
        "        input_sequences_batch, output_sequences_batch, artists_batch, sequences_lengths = post_processed_batch_tuple\n",
        "\n",
        "        output_sequences_batch_var = output_sequences_batch.contiguous().view(-1).cuda()\n",
        "        \n",
        "        \n",
        "        input_sequences_batch_var = input_sequences_batch.cuda()\n",
        "        artists_batch_var = artists_batch.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits, _ = rnn(input_sequences_batch_var, artists_batch_var, sequences_lengths)\n",
        "        \n",
        "        loss = criterion(logits, output_sequences_batch_var)\n",
        "        loss.backward()\n",
        "        \n",
        "        liveloss_train.update({'Training loss': loss.item()})\n",
        "        liveloss_train.draw()\n",
        "\n",
        "        #torch.nn.utils.clip_grad_norm(rnn.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "    #print(sample_from_rnn_conditionally(artist_label=trainset.artists_list.index(\"Kanye West\")))\n",
        "    torch.save(rnn.state_dict(), 'conditional_rnn.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-e96de4e9b582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequences_batch_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists_batch_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sequences_batch_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-6e5e889177ee>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_sequences, input_sequences_conditions, input_sequences_lengths, hidden)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Here we run rnns only on non-padded regions of the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_combined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequences_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unpack (back to padded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    630\u001b[0m                            \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                            ):\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[1;32m    634\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    205\u001b[0m             raise RuntimeError(\n\u001b[1;32m    206\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 207\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 1024, got 82"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqX7LVeNveSm"
      },
      "source": [
        "print(sample_from_rnn_conditionally(artist_label=trainset.artists_list.index(\"Eminem\"), starting_sting='A', temperature=0.5))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}